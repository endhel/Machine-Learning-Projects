{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digits Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"img/digits.gif\">\n",
    "</p>\n",
    "\n",
    "The MNIST database contains binary images of **handwritten digits**. The original black and white images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. The images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.The database has a training set of 60,000 examples, and a test set of 10,000 examples. There are 10 classes (one for each of the 10 digits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "import scikitplot        as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network  import MLPClassifier\n",
    "from sklearn.svm             import SVC\n",
    "\n",
    "from mnist import MNIST\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine with \n",
    "def rbf_model( X_train, X_test, y_train, y_test, cv, MAX_EVAL, param ):\n",
    "    \n",
    "    final_result = {\n",
    "        'Regularization': [],\n",
    "        'Gamma': [],\n",
    "        'Tol': [],\n",
    "        'Max_iter': [],\n",
    "        'Hold_out': [],\n",
    "        'Cross_validation': []\n",
    "    }\n",
    "    \n",
    "    for i in range( MAX_EVAL ):\n",
    "        # choose values for parameters randomly\n",
    "        hp = { k: random.sample( v, 1 )[0] for k, v in param.items() }\n",
    "        final_result['Regularization'].append(hp['C'])\n",
    "        final_result['Gamma'].append(hp['gamma'])\n",
    "        final_result['Tol'].append(hp['tol'])\n",
    "        final_result['Max_iter'].append(hp['max_iter'])\n",
    "        \n",
    "        # model\n",
    "        model_rbf = SVC( C = hp['C'],\n",
    "                         gamma = hp['gamma'],\n",
    "                         tol = hp['tol'],\n",
    "                         max_iter = hp['max_iter'],\n",
    "                         random_state = 33)\n",
    "        \n",
    "        # fit and training\n",
    "        y_pred = model_rbf.fit( X_train, y_train ).predict( X_test )\n",
    "        \n",
    "        # performance - hold-out\n",
    "        confusion_matrix( y_test, y_pred )\n",
    "        \n",
    "        # performance - cross validation\n",
    "        result_cv = cross_val_score( model_rbf, X_train, y_train, cv=cv )\n",
    "        print( 'Performance média: ', np.mean( result_cv ) )\n",
    "        print( 'Desvio padrão: ', np.std( result_cv ) )\n",
    "        \n",
    "        final_result['Hold_out'].append( result )\n",
    "        final_result['Cross_validation'].append( result )\n",
    "        \n",
    "    print( pd.DataFrame( final_result ) )\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Multilayer Perceptron\n",
    "def mlp_model( X_train, X_test, y_train, y_test, cv, MAX_EVAL, param ):\n",
    "    \n",
    "    final_result = {\n",
    "        'Hidden_layer_sizes': [],\n",
    "        'Activation': [],\n",
    "        'Solver': [],\n",
    "        'Max_iter': [],\n",
    "        'Hold_out': [],\n",
    "        'Cross_validation': []\n",
    "    }\n",
    "    \n",
    "    for i in range( MAX_EVAL ):\n",
    "        # choose values for parameters randomly\n",
    "        hp = { k: random.sample( v, 1 )[0] for k, v in param.items() }\n",
    "        final_result['Hidden_layer_sizes'].append(hp['hls'])\n",
    "        final_result['Activation'].append(hp['activation'])\n",
    "        final_result['Solver'].append(hp['solver'])\n",
    "        final_result['Max_iter'].append(hp['max_iter'])\n",
    "        \n",
    "        # model\n",
    "        model_mlp = MLPClassifier( hidden_layer_sizes = hp['hls'],\n",
    "                         activation = hp['activation'],\n",
    "                         solver = hp['solver'],\n",
    "                         max_iter = hp['max_iter'] )\n",
    "        \n",
    "        # fit and training\n",
    "        y_pred = model_mlp.fit( X_train, y_train ).predict( X_test )\n",
    "        \n",
    "        # performance - hold-out\n",
    "        confusion_matrix( y_test, y_pred )\n",
    "        \n",
    "        # performance - cross validation\n",
    "        result_cv = cross_val_score( model_mlp, X_train, y_train, cv=cv )\n",
    "        print( 'Performance média: ', np.mean( result_cv ) )\n",
    "        print( 'Desvio padrão: ', np.std( result_cv ) )\n",
    "        \n",
    "        final_result['Hold_out'].append( result )\n",
    "        final_result['Cross_validation'].append( result )\n",
    "        \n",
    "    print( pd.DataFrame( final_result ) )\n",
    "    \n",
    "    return None\n",
    "        \n",
    "    \n",
    "\n",
    "# Plot confusion matrix\n",
    "def confusion_matrix( y, predictions ):\n",
    "    skplt.metrics.plot_confusion_matrix( y, predictions )\n",
    "    plt.figure( figsize=(12, 8) )\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "mndata = MNIST( 'datasets/images_handwritten_digits' )\n",
    "\n",
    "image_train, label_train = mndata.load_training( )\n",
    "image_test, label_test = mndata.load_testing( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      ".................@@.........\n",
      "................@@@.........\n",
      "................@@@.........\n",
      "................@@@.........\n",
      "...............@@@@.........\n",
      "...............@@@@.........\n",
      "...............@@@@.........\n",
      "...............@@@..........\n",
      "..............@@@@..........\n",
      ".............@@@@@..........\n",
      ".............@@@@...........\n",
      "...........@@@@@............\n",
      "...........@@@@@............\n",
      "..........@@@@@.............\n",
      ".........@@@@@..............\n",
      ".........@@@@@..............\n",
      ".........@@@@@..............\n",
      ".........@@@@...............\n",
      ".........@@@................\n",
      ".........@@.................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n"
     ]
    }
   ],
   "source": [
    "# View an image\n",
    "index = random.randrange( 0, len( image_train ) ) \n",
    "print( mndata.display( image_train[index] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation\n",
    "image_train = pd.DataFrame( image_train )\n",
    "image_test = pd.DataFrame( image_test )\n",
    "label_train = pd.DataFrame( label_train )\n",
    "label_test = pd.DataFrame( label_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining image Dataframes\n",
    "X = pd.concat( [image_train, image_test], ignore_index=True )\n",
    "\n",
    "# Joining target Dataframes\n",
    "y = pd.concat( [label_train, label_test], ignore_index=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas:  70000\n",
      "Número de colunas:  784\n"
     ]
    }
   ],
   "source": [
    "# Data dimensions\n",
    "print('Número de linhas: ', X.shape[0])\n",
    "print('Número de colunas: ', X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Columns: 784 entries, 0 to 783\n",
      "dtypes: int64(784)\n",
      "memory usage: 418.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Data types\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783    0\n",
       "268    0\n",
       "266    0\n",
       "265    0\n",
       "264    0\n",
       "      ..\n",
       "520    0\n",
       "519    0\n",
       "518    0\n",
       "517    0\n",
       "0      0\n",
       "Length: 784, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing values\n",
    "X.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "X = pd.DataFrame( MinMaxScaler().fit_transform( X ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Split dataframe into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0. Machine Learning Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and number of iterations\n",
    "param = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': [-1, 200, 1000, 5000]\n",
    "}\n",
    "\n",
    "MAX_EVAL = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1. k = 5 for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_model( X_train, X_test, y_train, y_test, 5, MAX_EVAL, param )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
